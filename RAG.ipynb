{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e2b25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.24.2\n",
      "  Downloading numpy-1.24.2-cp310-cp310-win_amd64.whl.metadata (5.6 kB)\n",
      "Downloading numpy-1.24.2-cp310-cp310-win_amd64.whl (14.8 MB)\n",
      "   ---------------------------------------- 0.0/14.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/14.8 MB 2.5 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.8/14.8 MB 6.1 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.3/14.8 MB 7.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.9/14.8 MB 8.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.4/14.8 MB 9.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.8/14.8 MB 10.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.4/14.8 MB 10.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.9/14.8 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.6/14.8 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 5.2/14.8 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.8/14.8 MB 11.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.3/14.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.9/14.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.3/14.8 MB 11.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 7.8/14.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.3/14.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.6/14.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.1/14.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.4/14.8 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.5/14.8 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.6/14.8 MB 10.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.7/14.8 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.3/14.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.6/14.8 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.9/14.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.5/14.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.8/14.8 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.4/14.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.8/14.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.5/14.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.6/14.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.6/14.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.6/14.8 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.7/14.8 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.0/14.8 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.2/14.8 MB 9.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.3/14.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.8/14.8 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.8/14.8 MB 8.3 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-1.24.2\n",
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install numpy==1.24.2\n",
    "%pip install spacy\n",
    "%pip install faiss-cpu\n",
    "%pip install -U sentence-transformers\n",
    "\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e339ebef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82754343-5796-4000-91ab-c9d586cd6226",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015bbca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9368cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "with open('./data-collection/data/chapter-data.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85368585",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddedData = []\n",
    "\n",
    "for entry in tqdm(data):\n",
    "    book_title = entry.get(\"book_title\", \"\")\n",
    "    chapter_name = entry.get(\"chapter_name\", \"\")\n",
    "    paragraphs = entry.get(\"paragraphs\", [])\n",
    "\n",
    "    for i, paragraph in enumerate(paragraphs):\n",
    "        doc = nlp(paragraph)\n",
    "        sentences = [sent.text for sent in doc.sents]\n",
    "        paragraphEmbed = model.encode(sentences)\n",
    "        paragraphEmbed = np.mean(paragraphEmbed, axis=0)\n",
    "\n",
    "        embeddedData.append({\n",
    "                \"book_title\": book_title,\n",
    "                \"chapter_name\": chapter_name,\n",
    "                \"paragraph\": paragraph,\n",
    "                \"embeddedParagraph\": paragraphEmbed\n",
    "            })\n",
    "        \n",
    "    break\n",
    "\n",
    "embeddings = np.array([info['embeddedParagraph'] for info in embeddedData])\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8269c4b-7c35-40f0-afc2-3b749bc705fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336873e5-8021-41f7-836f-0c99bdd397a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa8ec2-6932-4e79-ab4f-53989d8d4642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b65ab5-ed0a-4626-946d-709b839aaebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fceb22e6-07ff-4b49-9ac8-8bc7f81a5544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (1.26.4)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.4-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (1.10.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (4.67.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (4.0.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\tanay\\anaconda3\\envs\\newpython310\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (2.19.0)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (2.19.0)\n",
      "Requirement already satisfied: keras in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (3.9.2)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-6.30.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting grpcio\n",
      "  Downloading grpcio-1.71.0-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting markdown\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting werkzeug\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting astunparse\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting gast\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting wrapt\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting namex\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree\n",
      "  Downloading optree-0.15.0-cp310-cp310-win_amd64.whl.metadata (49 kB)\n",
      "Collecting rich\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tensorboard-data-server\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (4.51.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (25.2.10)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tanay\\anaconda3\\envs\\newpython310\\lib\\site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tanay\\anaconda3\\envs\\newpython310\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.1.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from werkzeug) (3.0.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tanay\\anaconda3\\envs\\newpython310\\lib\\site-packages (from astunparse) (0.45.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tanay\\anaconda3\\envs\\newpython310\\lib\\site-packages (from rich) (2.15.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: networkx in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\tanay\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Using cached numpy-2.1.3-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading grpcio-1.71.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 1.6/4.3 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.1/4.3 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.6/4.3 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.4/4.3 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.9/4.3 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Downloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading wrapt-1.17.2-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp310-cp310-win_amd64.whl (297 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, markdown-it-py, rich\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed astunparse-1.6.3 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 namex-0.0.8 numpy-2.1.3 opt-einsum-3.4.0 optree-0.15.0 protobuf-5.29.4 rich-14.0.0 tensorboard-data-server-0.7.2 tensorflow-io-gcs-filesystem-0.31.0 termcolor-3.0.1 werkzeug-3.1.3 wrapt-1.17.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\tanay\\AppData\\Roaming\\Python\\Python310\\site-packages\\~.mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\tanay\\AppData\\Roaming\\Python\\Python310\\site-packages\\~=mpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade \\\n",
    "    numpy \\\n",
    "    faiss-cpu \\\n",
    "    tqdm \\\n",
    "    sentence-transformers \\\n",
    "    absl-py \\\n",
    "    tensorflow \\\n",
    "    tensorboard \\\n",
    "    keras \\\n",
    "    protobuf \\\n",
    "    grpcio \\\n",
    "    markdown \\\n",
    "    werkzeug \\\n",
    "    astunparse \\\n",
    "    gast \\\n",
    "    google-pasta \\\n",
    "    libclang \\\n",
    "    opt-einsum \\\n",
    "    tensorflow-io-gcs-filesystem \\\n",
    "    termcolor \\\n",
    "    wrapt \\\n",
    "    namex \\\n",
    "    optree \\\n",
    "    rich \\\n",
    "    tensorboard-data-server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae7688f2-7ba4-4202-8f16-abb575551caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tanay\\AppData\\Roaming\\Python\\Python310\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a75933e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanay\\anaconda3\\envs\\py310\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tanay\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "100%|██████████| 2601/2601 [04:23<00:00,  9.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Load Data ---\n",
    "with open('./data-collection/data/chapter-data.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# --- Step 2: Load Embedding Model ---\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# --- Step 3: Embed Data ---\n",
    "embeddedData = []\n",
    "\n",
    "def naive_sentence_split(paragraph):\n",
    "    # Simple sentence splitter (replace with nltk.sent_tokenize for better accuracy)\n",
    "    return [sent.strip() for sent in paragraph.split('.') if sent.strip()]\n",
    "\n",
    "for entry in tqdm(data):\n",
    "    book_title = entry.get(\"book_title\", \"\")\n",
    "    chapter_name = entry.get(\"chapter_name\", \"\")\n",
    "    paragraphs = entry.get(\"paragraphs\", [])\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        sentences = naive_sentence_split(paragraph)\n",
    "        sentence_embeddings = model.encode(sentences)\n",
    "        paragraph_embedding = np.mean(sentence_embeddings, axis=0)\n",
    "\n",
    "        embeddedData.append({\n",
    "            \"book_title\": book_title,\n",
    "            \"chapter_name\": chapter_name,\n",
    "            \"paragraph\": paragraph,\n",
    "            \"embeddedParagraph\": paragraph_embedding\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f7f0b2f-e3be-4ba8-a4cf-fbd6dab3a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Build FAISS Index ---\n",
    "embeddings = np.array([info['embeddedParagraph'] for info in embeddedData])\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2c05df9-e39d-4cc3-831f-94753f9ebf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, \"faiss_index.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ffd2912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Book: BOOK XI. THE VARIOUS KINDS OF INSECTS.\n",
      "📖 Chapter: CHAP. 34.—THE BEETLE. THE GLOW-WORM. OTHER KINDS OF BEETLES.\n",
      "📄 Paragraph: Some insects, for the preservation of their wings, are covered with a erust<@1> the beetle, for instance, the wing of which is peculiarly fine and frail. To these insects a sting has been denied by Nature; but in one large kind<@2> we find horns of a remarkable length, two-pronged at the extremities, and forming pincers, which the animal closes when it is its intention to bite. These beetles are suspended from the neck of infants by way of remedy against certain maladies: Nigidius calls them \"lucani.\" There is another kind<@3> of beetle, again, which, as it goes backwards with its feet, rolls the dung into large pellets, and then deposits in them the maggots which form its young, as in a sort of nest, to protect them against the rigours of winter. Some, again, fly with a loud buzzing or a drony noise, while others<@4> burrow numerous holes in the hearths and out in the fields, and their shrill chirrup is to be heard at night.\n",
      "--------------------------------------------------------------------------------\n",
      "📘 Book: BOOK XI. THE VARIOUS KINDS OF INSECTS.\n",
      "📖 Chapter: CHAP. 34.—THE BEETLE. THE GLOW-WORM. OTHER KINDS OF BEETLES.\n",
      "📄 Paragraph: The wings of all insects are formed without<@10> any division in them, and they none of them have a tail,<@11> with the exception of the scorpion; this, too, is the only one among them that has arms,<@12> together with a sting in the tail. As to the rest of the insects, some of them have the sting in the mouth, the gad-fly for instance, or the \"tabanus,\" as some persons choose to call it: the same is the case, too, with the gnat and some kinds of flies. All these insects have their stings situate in the mouth instead<@13> of a tongue; but in some the sting is not pointed, being formed not for pricking, but for the purpose of suction: this is the case more especially with flies, in which it is clear that the tongue<@14> is nothing more than a tube. These insects, too, have no teeth. Others, again, have little horns protruding in front of the eyes, but without any power in them; the butterfly, for instance. Some insects are destitute of wings, such as the scolopendra, for instance.<@15>\n",
      "--------------------------------------------------------------------------------\n",
      "📘 Book: BOOK XI. THE VARIOUS KINDS OF INSECTS.\n",
      "📖 Chapter: CHAP. 33. (28.)—THE WINGS OF INSECTS.\n",
      "📄 Paragraph: There are some insects which have two wings, flies, for instance; others, again, have four, like the bee. The wings of the grasshopper are membranous. Those insects which are armed with a sting in the abdomen, have four wings. None of those which have a sting in the mouth, have more than two wings. The former have received the sting for the purpose of defending themselves, the latter for the supplying of their wants. If pulled from off the body, the wings of an insect will not grow again; no insect which has a sting inserted in its body, has two wings only.\n",
      "--------------------------------------------------------------------------------\n",
      "📘 Book: BOOK XI. THE VARIOUS KINDS OF INSECTS.\n",
      "📖 Chapter: CHAP. 35.—LOCUSTS.\n",
      "📄 Paragraph: (29.) These creatures lay their eggs in large masses, in the autumn, thrusting the end of the tail into holes which they form in the ground. These eggs remain underground throughout the winter, and in the ensuing year, at the close of spring, small locusts issue from them, of a black colour, and crawling along without legs<@1> and wings. Hence it is that a wet spring destroys their eggs, while, if it is dry, they multiply in great abundance. Some persons maintain that they breed twice a year, and die the same number of times; that they bring forth at the rising<@2> of the Vergiliæ, and die at the rising of the Dog-star,<@3> after which others spring up in their places: according to some, it is at the setting<@4> of Arcturus that the second litter is produced. That the mothers die the moment they have brought forth, is a well-known fact, for a little worm immediately grows about the throat, which chokes them: at the same time, too, the males perish as well. This insect, which thus dies through a cause apparently so trifling, is able to kill a serpent by itself, when it pleases, by seizing its jaws with its teeth.<@5> Locusts are only produced in champaign places, that are full of chinks and crannies. In India, it is said that they attain the length of three<@6> feet, and that the people dry the legs and thighs, and use them for saws. There is another mode, also, in which these creatures perish; the winds carry them off in vast swarms, upon which they fall into the sea or standing waters, and not, as the ancients supposed, because their wings have been drenched by the dampness of the night. The same authors have also stated, that they are unable to fly during the night, in consequence of the cold, being ignorant of the fact, that they travel over lengthened tracts of sea for many days together, a thing the more to be wondered at, as they have to endure hunger all the time as well, for this it is which causes them to be thus seeking pastures in other lands. This is looked upon as a plague<@7> inflicted by the anger of the gods; for as they fly they appear to be larger than they really are, while they make such a loud noise with their wings, that they might be readily supposed to be winged creatures of quite another species. Their numbers, too, are so vast, that they quite darken the sun; while the people below are anxiously following them with the eye, to see if they are about to make a descent, and so cover their lands. After all, they have the requisite energies for their flight; and, as though it had been but a trifling matter to pass over the seas, they cross immense tracts of country, and cover them in clouds which bode destruction to the harvests. Scorching numerous objects by their very contact, they eat away everything with their teeth, the very doors of the houses even.\n",
      "--------------------------------------------------------------------------------\n",
      "📘 Book: BOOK XI. THE VARIOUS KINDS OF INSECTS.\n",
      "📖 Chapter: CHAP. 112. (51.)—THE DIFFERENT VOICES OF ANIMALS.\n",
      "📄 Paragraph: Aristotle<@1> is of opinion that no animal has a voice which does not respire, and that hence it is that there is no voice in insects, but only a noise, through the circulation of the air in the interior, and its resounding, by reason of its compression. Some insects, again, he says, emit a sort of humming noise, such as the bee, for instance; others a shrill, long-drawn note, like the grasshopper, the two cavities beneath the thorax receiving the air, which, meeting a moveable membrane within, emits a sound by the attrition.—Also that flies, bees, and other insects of that nature, are only heard while they are flying, and cease to be heard the moment they settle, and that the sound which they emit proceeds from the friction and the air within them, and not from any act of respiration. At all events, it is generally believed that the locust emits a sound by rubbing together the wings and thighs, and that among the aquatic animals the scallop makes a certain noise as it flies.<@2> Mollusks, however, and the testaceous animals have no voice and emit no sounds. As for the other fishes, although they are destitute of lungs and the tracheal artery, they are not entirely without the power of emitting certain sounds: it is only a mere joke to say that the noise which they make is produced by grating their teeth together. The fish, too, that is found in the river Acheloüs, and is known as the boar-fish,<@3> makes a grunting noise, as do some others which we have previously<@4> mentioned. The oviparous animals hiss: in the serpent this hissing is prolonged, in the tortoise it is short and abrupt. Frogs make a peculiar noise of their own, as already stated;<@5> unless, indeed, this, too, is to be looked upon as a matter of doubt; but their noise originates in the mouth, and not in the thorax. Still, however, in reference to this subject, the nature of the various localities exercises a very considerable influence, for in Macedonia, it is said, the frogs are dumb, and the same in reference to the wild boars there. Among birds, the smaller ones chirp and twitter the most, and more especially about the time of pairing. Others, again, exercise their voice while fighting, the quail, for instance; others before they begin to fight, such as the partridge; and others when they have gained the victory, the dunghill cock, for instance. The males in these species have a peculiar note of their own, while in others, the nightingale for example, the male has the same note as the female.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Perform a Search Query ---\n",
    "query = \"Do cockroaches fly?\"\n",
    "query_embedding = model.encode([query])\n",
    "D, I = index.search(np.array(query_embedding), k=5)\n",
    "\n",
    "# --- Step 6: Retrieve Top-K Results ---\n",
    "retrieved_paragraphs = [embeddedData[idx] for idx in I[0]]\n",
    "\n",
    "# --- Step 7: Display Results ---\n",
    "for result in retrieved_paragraphs:\n",
    "    print(f\"📘 Book: {result['book_title']}\")\n",
    "    print(f\"📖 Chapter: {result['chapter_name']}\")\n",
    "    print(f\"📄 Paragraph: {result['paragraph']}\\n{'-'*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f85c034b-aa1b-49e0-8bd9-0f1ddd593317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"  # Replace with your actual key\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce563807-44a3-4942-9827-1de54fb8f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6: Define Pliny the Elder Prompt ---\n",
    "pliny_prompt = \"\"\"You are Pliny the Elder, the ancient Roman author, naturalist, and philosopher. \n",
    "You embody his inquisitive mind, dedication to the study of the natural world, and his vast knowledge of the cosmos, \n",
    "geography, and science.\n",
    "\n",
    "Your tone is methodical, factual, and reflects the style of Roman literature. \n",
    "You approach the world with a sense of wonder and a quest for understanding, often writing with reverence for nature's complexity \n",
    "and the wisdom of ancient knowledge. While your style is rooted in the classical world, you communicate your insights with clarity \n",
    "and precision.\n",
    "\n",
    "You often rely on historical context, anecdotes from Roman society, and empirical observation to explain complex phenomena. \n",
    "Your humor is subtle, but sometimes dry and rooted in irony, highlighting the contradictions and mysteries of life.\n",
    "\n",
    "When answering questions, you:\n",
    "- Prioritize detailed, factual knowledge from your observations of the natural world and history.\n",
    "- Offer pragmatic perspectives, often connecting topics to the knowledge of your time or using the teachings of the great \n",
    "  Roman thinkers.\n",
    "- Challenge misconceptions, but with the gentleness of a scholar eager to impart wisdom, rather than confrontationally.\n",
    "- Occasionally inject humor, but in the style of an ancient Roman philosopher, with a focus on irony or intellectual \n",
    "  humor.\n",
    "- Your responses should be **short, witty, and educational**. Keep your answers brief and avoid excessive elaboration. \n",
    "\n",
    "You do not break character. Stay in Pliny the Elder's mindset and manner of speech at all times.\n",
    "\n",
    "Below, you will be given a **user query** along with some **context**. The context is relevant information that may help you answer the query. Please use the provided context to craft your response, but also feel free to draw from your own knowledge to supplement the answer if necessary.\n",
    "\n",
    "**User Query**: {query}\n",
    "\n",
    "**Context**: {context}\n",
    "\n",
    "Answer the question using the context provided, and feel free to elaborate on the subject using your own expertise and historical knowledge. Your answer should be **short, concise**, and **educational**, while avoiding unnecessary elaboration.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18831dce-7b70-4fa5-86e1-96ac91c8d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 7: Function to Call LLM with Context from RAG ---\n",
    "def get_chatgpt_response(query, context):\n",
    "    \"\"\"\n",
    "    This function will call OpenAI's model with the Pliny the Elder system prompt, user query, \n",
    "    and provided context to generate an answer.\n",
    "    \"\"\"\n",
    "    context_text = \"\\n\\n\".join([f\"Book: {res['book_title']} | Chapter: {res['chapter_name']} | Paragraph: {res['paragraph']}\" for res in context])\n",
    "\n",
    "    print(\"🤖 Sending to ChatGPT...\")\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4\",  # Use the appropriate model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": pliny_prompt},  # Pliny's prompt\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{context_text}\\n\\nQuery: {query}\"}  # The query with the context\n",
    "        ],\n",
    "        max_tokens=200,  # Adjust based on desired response length\n",
    "        temperature=0.4  # Controlled creativity\n",
    "    )\n",
    "\n",
    "    response_text = completion.choices[0].message.content\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8135eda-8161-47b8-924e-971d98a327d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 8: Query Handling and RAG ---\n",
    "def query_rag(query):\n",
    "    \"\"\"\n",
    "    Given a user query, this function retrieves the top-N relevant paragraphs using FAISS \n",
    "    and then sends them along with the query to the LLM to generate an answer.\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve the top-N relevant paragraphs using FAISS\n",
    "    query_embedding = model.encode([query])\n",
    "    k = 3  # Number of nearest neighbors to retrieve\n",
    "    D, I = index.search(np.array(query_embedding), k)\n",
    "\n",
    "    # Step 2: Collect the top-N results\n",
    "    retrieved_paragraphs = [embeddedData[idx] for idx in I[0]]\n",
    "\n",
    "    # Step 3: Pass context (retrieved paragraphs) and query to LLM\n",
    "    return get_chatgpt_response(query, retrieved_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e5bcaae-3a80-4b55-9c10-a68e009dc941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Sending to ChatGPT...\n",
      "Generated Answer: Ah, the cockroach, a creature of resilience and adaptability. While it may not be the most esteemed of creatures in the eyes of many, it is indeed capable of a form of flight. However, it should be noted that this is more akin to gliding or fluttering than the soaring of an eagle or the fluttering of a butterfly. As for jumping, it is not a common behavior for a cockroach, as they prefer to scuttle along surfaces with their nimble legs. Thus, in essence, they may fly, but they do not jump in the manner of, say, a locust.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 9: Example Query ---\n",
    "query = \"Do cockroaches jump or fly?\"\n",
    "answer = query_rag(query)\n",
    "print(\"Generated Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571dbf9b-aa28-4168-b0fa-d94e8e7377e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
